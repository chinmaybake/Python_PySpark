{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chinmay Bake Machine Learning Assignment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "spark=SparkSession.builder.appName('Logistic_Regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF=spark.read.csv(r'D:\\train.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, determine if there are any missing values and if so, how many, for each variable, including the output variable, e.g. for variable age\n",
    "\n",
    "main_DF.where(main_DF['Age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF.where(main_DF['Pclass'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF.where(main_DF['Sex'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF.where(main_DF['Embarked'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF.where(main_DF['Survived'].isNull()).count()\n",
    "\n",
    "'''Thus except for \"Age\" column, no other input or out variables have a missing value'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+--------+\n",
      "|summary|               Age|            Pclass|   Sex|Embarked|\n",
      "+-------+------------------+------------------+------+--------+\n",
      "|  count|               714|               891|   891|     891|\n",
      "|   mean| 29.69911764705882| 2.308641975308642|  null|    null|\n",
      "| stddev|14.526497332334035|0.8360712409770491|  null|    null|\n",
      "|    min|              0.42|                 1|female|       C|\n",
      "|    max|              80.0|                 3|  male|       S|\n",
      "+-------+------------------+------------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, you will have to find the average age for the data in the dataframe. You may to do this with the describe() function of the dataframe.\n",
    "\n",
    "main_DF.describe().select('summary','Age','Pclass','Sex','Embarked').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, you will need to replace the null value for age with the average value. \n",
    "\n",
    "main_DF= main_DF.fillna({'Age':29.70})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF.where(main_DF['Age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "# 1) What is the shape of the data contained in training.csv?\n",
    "\n",
    "print((main_DF.count(),len(main_DF.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) What features (or attributes) are recorded for each passenger in training.csv?\n",
    "\n",
    "main_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Provide a schema of the columns to be included in your model for this assignment.  Comment on columns that may require transformation(s). \n",
    "\n",
    "main_DF.printSchema()\n",
    "\n",
    "'''Columns \"Sex\" and \"Embarked\" do not have a numeric data type and are categorical. For a Machine Learning \n",
    "model to process these variables, they need to be converted to a numeric data type. For this purpose, we utilise \n",
    "the concept of Dummy Variables where each category in the variable would represented by a dummy numeric variable.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Less than 50% passengers survived the voyage.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Comment on the balance of data in training.csv with regards to each input variable as well as your target variable. \n",
    "#Support your comments with appropriate statistics. \n",
    "\n",
    "main_DF.groupBy('Survived').count().show()\n",
    "\n",
    "'''Less than 50% passengers survived the voyage. Hence we have more data with passangers who did not survived \n",
    "than the passangers who did.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|Survived|  avg(PassengerId)|avg(Survived)|       avg(Pclass)|          avg(Age)|         avg(SibSp)|        avg(Parch)|         avg(Fare)|\n",
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|       1|444.36842105263156|          1.0|1.9502923976608186|28.549912280701747|0.47368421052631576|0.4649122807017544| 48.39540760233917|\n",
      "|       0| 447.0163934426229|          0.0|2.5318761384335153| 30.41530054644817| 0.5537340619307832|0.3296903460837887|22.117886885245877|\n",
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4) \n",
    "\n",
    "main_DF.groupBy('Survived').mean().show()\n",
    "\n",
    "'''Average age of the passangers who survived and the ones who did not is fairly similar.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4) \n",
    "\n",
    "main_DF.groupBy('Pclass').count().show()\n",
    "\n",
    "'''We observe that the majority of passengers belonged to third class, followed by the ones who opted \n",
    "first class and the lastly second class. Hence there is a substantial imbalance in the count within the categories.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4) \n",
    "\n",
    "df.groupBy('Sex').count().show()\n",
    "\n",
    "'''There were more males than females on the voyage.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   78|\n",
      "|       C|  168|\n",
      "|       S|  645|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4) \n",
    "\n",
    "df.groupBy('Embarked').count().show()\n",
    "\n",
    "'''The data is heavily biased towards Southampton as the port of embarkation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+-----------------+------------------+-------------------+-------------------+------------------+\n",
      "|   Sex|  avg(PassengerId)|      avg(Survived)|      avg(Pclass)|          avg(Age)|         avg(SibSp)|         avg(Parch)|         avg(Fare)|\n",
      "+------+------------------+-------------------+-----------------+------------------+-------------------+-------------------+------------------+\n",
      "|female|431.02866242038215| 0.7420382165605095|2.159235668789809|28.216878980891703| 0.6942675159235668| 0.6496815286624203| 44.47981783439487|\n",
      "|  male| 454.1473136915078|0.18890814558058924|2.389948006932409|  30.5060138648181|0.42980935875216636|0.23570190641247835|25.523893414211418|\n",
      "+------+------------------+-------------------+-----------------+------------------+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4) \n",
    "\n",
    "df.groupBy('Sex').mean().show()\n",
    "\n",
    "'''The average survival value for females is much closer to 1 than that of the males.\n",
    "This possibly implies that more females managed surviving the disaster.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Perform the transformations, if any, identified in step # 3.\n",
    "#Perform feature engineering if and where needed, including Vectorization of relevant input variables. \n",
    "\n",
    "gender_indexer =StringIndexer(inputCol=\"Sex\", outputCol=\"Gen_Numb\").fit(main_DF)\n",
    "gender_DF = gender_indexer.transform(main_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_indexer =StringIndexer(inputCol=\"Embarked\", outputCol=\"Emb_Numb\").fit(gender_DF)\n",
    "embarked_DF = embarked_indexer.transform(gender_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoder=OneHotEncoder(inputCol=\"Gen_Numb\", outputCol=\"Gender_Dummy_Vector\")\n",
    "GenderEncoded_DF=gender_encoder.transform(embarked_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_encoder=OneHotEncoder(inputCol=\"Emb_Numb\", outputCol=\"Embarked_Dummy_Vector\")\n",
    "EmbarkedEncoded_DF=embarked_encoder.transform(GenderEncoded_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assember_DF = VectorAssembler(inputCols=['Age','Pclass','Gender_Dummy_Vector','Embarked_Dummy_Vector'], outputCol=\"features\")\n",
    "Vector_DF = df_assembler.transform(EmbarkedEncoded_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Gen_Num: double (nullable = false)\n",
      " |-- Emb_Num: double (nullable = false)\n",
      " |-- Gen_Numb: double (nullable = false)\n",
      " |-- Emb_Numb: double (nullable = false)\n",
      " |-- Gender_Dummy_Vector: vector (nullable = true)\n",
      " |-- Embarked_Dummy_Vector: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Provide a printout of the schema of your feature-engineered data.\n",
    "Vector_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) To train and then test your model, split the data from training.csv into training and test datasets using an 80/20 split. \n",
    "\n",
    "Model_DF=Vector_DF.select(['features','Survived'])\n",
    "train_DF,test_DF=Model_DF.randomSplit([0.80,0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data count: 705   Testing data count: 186\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data count:\",train_DF.count(),\" \",\"Testing data count:\",test_DF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  276|\n",
      "|       0|  429|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_DF.groupBy('Survived').count().show()\n",
    "\n",
    "#balance of data\n",
    "'''We have more data points with target value 0 than with 1.'''\n",
    "\n",
    "#Balance of target classes\n",
    "'''The ratio of count of 1 to 0 in the overall dataset is 0.62 and in the training dataset is 0.64\n",
    "Therefore equivalent proportions of data is included in the training dataset and it correctly represents the overall \n",
    "data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|   66|\n",
      "|       0|  120|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_DF.groupBy('Survived').count().show()\n",
    "\n",
    "'''The test data set has a slight imbalance in the proportion of the target variables when compared with the overall data but \n",
    "the data is better distributed within the binary categories.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------------------------------------+\n",
      "|Survived|prediction|probability                             |\n",
      "+--------+----------+----------------------------------------+\n",
      "|1       |1.0       |[0.25581765877814716,0.7441823412218529]|\n",
      "|1       |1.0       |[0.26212697221755493,0.7378730277824451]|\n",
      "|1       |1.0       |[0.26212697221755493,0.7378730277824451]|\n",
      "|0       |1.0       |[0.27504279752519617,0.7249572024748039]|\n",
      "|0       |1.0       |[0.2951397358096188,0.7048602641903812] |\n",
      "|1       |1.0       |[0.3020252651677627,0.6979747348322373] |\n",
      "|1       |1.0       |[0.13957760734216204,0.860422392657838] |\n",
      "|0       |1.0       |[0.35789587102105347,0.6421041289789464]|\n",
      "|0       |1.0       |[0.35789587102105347,0.6421041289789464]|\n",
      "|0       |1.0       |[0.35789587102105347,0.6421041289789464]|\n",
      "+--------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7) Build and train the Logistic Regression model. Generate a list of predictions for passengers survival status (survival = 1) based on the trained model. \n",
    "# Display actual, predicted, and probability values for the first 10 rows only\n",
    "\n",
    "log_reg=LogisticRegression(labelCol='Survived').fit(train_DF)\n",
    "Training_Results=log_reg.evaluate(training_df).predictions\n",
    "Training_Results.select('Survived','prediction','probability').show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on these results, comment on the performance of the model? Is the model predicting likelihood of survival with high probability?\n",
    "\n",
    "'''The first value in the probability represents 0(did not survive) and the second one represents the \n",
    "one who survived; we could observe that for the first 10 records displayed, all the second probability values\n",
    "are greater than the first one. That is essentially the resaon why all the predicted values are equal to 1. \n",
    " Based on evaluating these specific records, the model performance is pretty average. The model has predicted \n",
    " half of the records correcly, while half of the predictions are False Positives.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Using the test data from the 80/20 split, evaluate the performance of your trained model. \n",
    "\n",
    "Testing_Results=log_reg.evaluate(test_DF).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and show the values for Accuracy, Recall, Precision, and an F1 score. \n",
    "\n",
    "tp = Testing_Results[(Testing_Results.Survived == 1) & (Testing_Results.prediction == 1)].count()\n",
    "tn = Testing_Results[(Testing_Results.Survived == 0) & (Testing_Results.prediction == 0)].count()\n",
    "fp = Testing_Results[(Testing_Results.Survived == 0) & (Testing_Results.prediction == 1)].count()\n",
    "fn = Testing_Results[(Testing_Results.Survived == 1) & (Testing_Results.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",float((tp+tn) /(tp+tn+fp+fn)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Rate: 0.7424242424242424\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall Rate:\",float(tp)/(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7205882352941176\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", float(tp) / (tp + fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7313432835820897\n"
     ]
    }
   ],
   "source": [
    "precision=float(tp) / (tp + fp)\n",
    "recall=float(tp)/(tp+fn)\n",
    "print(\"F1 Score:\",2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The model yeilds an accuracy of 80% which could be considered as quite good. Accuracy although\\nis dependent on how balanced the input data is. Therefore we compute the recall rate of the model.\\nEvery time the model makes a prediction, 74% of the Postives would be correctly predicted.'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment of general usefulness of the model in predicting the survival status of passengers given their age, gender, pclass and embarked values.\n",
    "\n",
    "'''The model yeilds an accuracy of 80% which could be considered as quite good. Accuracy although is dependent on how \n",
    "balanced the input data is. Therefore we compute the precision of the model for better evauluation. Every time \n",
    "the model makes a prediction, 74% of the Postives (survived) are correctly predicted. We have the recall rate and precision \n",
    "in the similar range; meaning that our input test data is pretty well balanced.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate ROC \n",
    "\n",
    "#a.obtain a summary of the model trained with training dataset. \n",
    "#Assuming that the instance of the logistic regression model fitted with training data is called â€˜log_reg\n",
    "\n",
    "training_summary = log_reg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.8500853011722578\n"
     ]
    }
   ],
   "source": [
    "#b From the training_summary, obtain and print the AUC value\n",
    "\n",
    "print(\"areaUnderROC: \" + str(training_summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798581560283688 Recall: 0.7985815602836879 Precision: 0.7969395642799602 F1 Score: 0.7970895590646272\n"
     ]
    }
   ],
   "source": [
    "#Accuracy, Precision, Recall and F1 obtained from summary\n",
    "\n",
    "print(\"Accuracy:\",training_summary.accuracy,\"Recall:\",training_summary.weightedRecall,\n",
    "      \"Precision:\",training_summary.weightedPrecision,\"F1 Score:\",training_summary.weightedFMeasure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comparing the evaluations for the test and train data, we observe a marginal difference in the accuracy of the model. \\nAll in all, we can observed that the model better predicts with training data owing to higher F1 score and precision values'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the AUC, Accuracy, Recall, Precision and F1 score calculated in this step, please discuss the performance of the trained model. \n",
    "\n",
    "'''Comparing the evaluations for the test and train data, we observe a marginal difference in the accuracy of the model. \n",
    "All in all, we can observe that the model better predicts with training data with a higher F1 score and better precision value.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
